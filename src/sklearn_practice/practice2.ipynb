{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc0ef0dd",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6606b429",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "script_dir = os.getcwd()\n",
    "project_root = os.path.abspath(os.path.join(script_dir, '..', '..'))\n",
    "input_filepath = os.path.join(project_root, 'data', 'housing.csv')\n",
    "\n",
    "housing_data = pd.read_csv(input_filepath)\n",
    "housing_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9228e978",
   "metadata": {},
   "source": [
    "# Removing NAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2097f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Before : \" , housing_data.isnull().sum(), \"\\n\")\n",
    "\n",
    "lowest_number_of_bedrooms = min(housing_data[\"total_bedrooms\"])\n",
    "print(f\"lowest_number_of_bedrooms : {lowest_number_of_bedrooms}\\n\")\n",
    "\n",
    "housing_data[\"total_bedrooms\"] = housing_data[\"total_bedrooms\"].fillna(lowest_number_of_bedrooms)\n",
    "\n",
    "print(\"After \" , housing_data.isnull().sum(),\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05306a4",
   "metadata": {},
   "source": [
    "# Removing OUTLIERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a411647a",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_house_value = housing_data[\"median_house_value\"]\n",
    "Q1, Q3 = median_house_value.quantile([0.25, 0.75])\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower_bound = max(0, Q1 - 1.5 * IQR)\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "print(f\"ðŸ“ˆ Housing value Statistics:\")\n",
    "print(f\"   Q1: â‚¹{Q1:,.2f}, Q3: â‚¹{Q3:,.2f}, IQR: â‚¹{IQR:,.2f}\")\n",
    "print(f\"   Bounds: [â‚¹{lower_bound:,.2f}, â‚¹{upper_bound:,.2f}]\")\n",
    "\n",
    "# Step 3: Cap outliers\n",
    "outliers_mask = (median_house_value < lower_bound) | (median_house_value > upper_bound)\n",
    "housing_data.loc[median_house_value < lower_bound, 'median_house_value'] = lower_bound\n",
    "housing_data.loc[median_house_value > upper_bound, 'median_house_value'] = upper_bound\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b17abc",
   "metadata": {},
   "source": [
    "# Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a2f92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Use axes[0,0] for plotting, not plt.scatter\n",
    "axes[0].scatter(x=housing_data[\"total_rooms\"], y=housing_data[\"median_house_value\"])\n",
    "axes[0].set_xlabel(\"Total Rooms\")\n",
    "axes[0].set_ylabel(\"Median House Value\")\n",
    "\n",
    "\n",
    "axes[1].boxplot(housing_data.select_dtypes(include=[\"number\"]).values)\n",
    "axes[1].set_xticklabels(housing_data.select_dtypes(include=[\"number\"]).columns, rotation=45)\n",
    "axes[1].set_title(\"Boxplot of Housing Data\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980679cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_data = housing_data.drop(housing_data.loc[housing_data[\"median_house_value\"] == 500001].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ffe7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_data = pd.get_dummies(housing_data, columns= [\"ocean_proximity\"], dtype=int)\n",
    "print(housing_data.shape)\n",
    "housing_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed67172",
   "metadata": {},
   "source": [
    "# Modeling started"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9d57f0",
   "metadata": {},
   "source": [
    "## Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e63a0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Prepare features and target\n",
    "X = housing_data.drop(\"median_house_value\", axis=1)\n",
    "Y = housing_data[\"median_house_value\"]\n",
    "print(\"X Columns:\", X.columns.tolist())\n",
    "print(f\"Dataset shape: {housing_data.shape}\")\n",
    "\n",
    "# Split the data\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    X, Y, test_size=0.2, random_state=42  # Added random_state for reproducibility\n",
    ")\n",
    "print(f\"Training set: {x_train.shape}, Testing set: {x_test.shape}\")\n",
    "print(f\"Training target: {y_train.shape}, Testing target: {y_test.shape}\")\n",
    "\n",
    "# Handle missing values if any\n",
    "if x_train.isnull().sum().any() or x_test.isnull().sum().any():\n",
    "    print(\"Warning: Missing values detected. Handling them...\")\n",
    "    x_train = x_train.fillna(x_train.mean())\n",
    "    x_test = x_test.fillna(x_train.mean())  # Use training stats for test set\n",
    "\n",
    "# Scale the data properly\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)  # Important: Use transform, not fit_transform\n",
    "\n",
    "print(f\"\\nScaling applied. Training set stats after scaling:\")\n",
    "print(f\"Mean: {x_train_scaled.mean():.2f}, Std: {x_train_scaled.std():.2f}\")\n",
    "\n",
    "# Fit model\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(x_train_scaled, y_train)\n",
    "\n",
    "# Calculate scores\n",
    "train_score = linear_model.score(x_train_scaled, y_train)\n",
    "test_score = linear_model.score(x_test_scaled, y_test)\n",
    "\n",
    "print(f\"\\nTraining RÂ² score: {train_score:.4f}\")\n",
    "print(f\"Testing RÂ² score: {test_score:.4f}\")\n",
    "\n",
    "# Feature importance analysis\n",
    "coef_df = pd.DataFrame({\n",
    "    'feature': x_train.columns,\n",
    "    'coefficient': linear_model.coef_,\n",
    "    'abs_coefficient': np.abs(linear_model.coef_)\n",
    "}).sort_values('abs_coefficient', ascending=False)\n",
    "\n",
    "print(\"\\nFeature Coefficients (sorted by importance):\")\n",
    "print(coef_df)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = linear_model.predict(x_test_scaled)\n",
    "\n",
    "# Calculate additional metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"\\nModel Performance Metrics:\")\n",
    "print(f\"RÂ² Score: {r2:.4f}\")\n",
    "print(f\"Mean Squared Error: {mse:,.2f}\")\n",
    "print(f\"Root Mean Squared Error: {rmse:,.2f}\")\n",
    "print(f\"Mean Absolute Error: {mae:,.2f}\")\n",
    "\n",
    "# Create comprehensive prediction dataframe\n",
    "prediction_df = pd.DataFrame({\n",
    "    \"actual\": y_test.values,\n",
    "    \"predicted\": y_pred,\n",
    "    \"residual\": y_test.values - y_pred,\n",
    "    \"absolute_error\": np.abs(y_test.values - y_pred)\n",
    "})\n",
    "\n",
    "# Calculate percentage error\n",
    "prediction_df[\"percentage_error\"] = (prediction_df[\"residual\"] / prediction_df[\"actual\"]) * 100\n",
    "prediction_df[\"absolute_percentage_error\"] = np.abs(prediction_df[\"percentage_error\"])\n",
    "\n",
    "print(f\"\\nPrediction Analysis:\")\n",
    "print(f\"Mean Absolute Percentage Error: {prediction_df['absolute_percentage_error'].mean():.2f}%\")\n",
    "print(f\"Max Absolute Percentage Error: {prediction_df['absolute_percentage_error'].max():.2f}%\")\n",
    "\n",
    "# Display sample predictions\n",
    "print(\"\\nSample Predictions (first 10):\")\n",
    "print(prediction_df.head(10).round(2))\n",
    "\n",
    "# Additional: Model intercept\n",
    "print(f\"\\nModel intercept: {linear_model.intercept_:.2f}\")\n",
    "\n",
    "# Optional: Check for potential overfitting\n",
    "if train_score - test_score > 0.1:\n",
    "    print(\"\\nWarning: Large gap between training and testing scores suggests potential overfitting\")\n",
    "else:\n",
    "    print(\"\\nTraining and testing scores are consistent\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2afb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)\n",
    "print(x_train.shape, x_test.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828dddeb",
   "metadata": {},
   "source": [
    "## Model training and fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c27d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Scale the data properly\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "\n",
    "# Fit model\n",
    "linear_model = LinearRegression().fit(x_train_scaled, y_train)\n",
    "\n",
    "# Calculate score on scaled data\n",
    "train_score = linear_model.score(x_train_scaled, y_train)\n",
    "print(\"Training score with proper scaling:\", train_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8bd91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef = pd.Series(linear_model.coef_, x_train.columns).sort_values()\n",
    "print(coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8e4414",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = linear_model.predict(x_test)\n",
    "prediction_df = pd.DataFrame({\"predicted\": y_pred, \"actual\": y_test})\n",
    "prediction_df.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
